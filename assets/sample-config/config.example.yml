version: 1
general:
  data_root: "~/modfetch-data"
  download_root: "~/Downloads/modfetch"
  partials_root: "~/Downloads/modfetch/.parts"   # optional override; else defaults to download_root/.parts
  placement_mode: "symlink"     # symlink | hardlink | copy
  quarantine: false
  allow_overwrite: false
  dry_run: false
  stage_partials: true           # write .part files under download_root/.parts (recommended)
  always_no_resume: false        # force fresh downloads by default (can override with CLI)

network:
  timeout_seconds: 60
  max_redirects: 5
  tls_verify: true
  user_agent: "modfetch/0.1"

concurrency:
  global_files: 4
  per_file_chunks: 4
  per_host_requests: 8
  chunk_size_mb: 8
  max_retries: 8
  backoff:
    min_ms: 200
    max_ms: 30000
    jitter: true

sources:
  huggingface:
    enabled: true
    token_env: "HF_TOKEN"      # resolved at runtime
  civitai:
    enabled: true
    token_env: "CIVITAI_TOKEN"

placement:
  apps:
    a1111:
      base: "/path/to/stable-diffusion-webui"
      paths:
        checkpoints: "models/Stable-diffusion"
        lora: "models/Lora"
        vae: "models/VAE"
        controlnet: "extensions/sd-webui-controlnet/models"
        embeddings: "embeddings"
    comfyui:
      base: "/path/to/ComfyUI"
      paths:
        checkpoints: "models/checkpoints"
        lora: "models/loras"
        vae: "models/vae"
        controlnet: "models/controlnet"
        embeddings: "models/embeddings"
    ollama:
      base: "~/.ollama"
      paths:
        models: "models"
    vllm:
      base: "~/Models/LLM"
      paths:
        models: "."
    lmstudio:
      base: "~/Library/Application Support/LM Studio"
      paths:
        models: "models"
  mapping:
    - match: "sd.checkpoint"
      targets:
        - app: "comfyui"
          path_key: "checkpoints"
        - app: "a1111"
          path_key: "checkpoints"
    - match: "sd.lora"
      targets:
        - app: "comfyui"
          path_key: "lora"
        - app: "a1111"
          path_key: "lora"
    - match: "llm.gguf"
      targets:
        - app: "ollama"
          path_key: "models"
        - app: "vllm"
          path_key: "models"
    - match: "generic"
      targets:
        - app: "vllm"
          path_key: "models"
classifier:
  rules:
    - regex: "^special"
      type: "sd.lora"

logging:
  level: "info"
  format: "human"
  file:
    enabled: false
    path: "~/modfetch-data/logs/modfetch.log"
    max_megabytes: 50
    max_backups: 3
    max_age_days: 14

metrics:
  prometheus_textfile:
    enabled: false
    path: ""

validation:
  require_sha256: false
  accept_md5_sha1_if_provided: false
  safetensors_deep_verify_after_download: true   # verify coverage/length for .safetensors after download; fail if not exact

